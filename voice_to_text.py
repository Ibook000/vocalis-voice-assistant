import sounddevice as sd
import numpy as np
import whisper
import torch
import wavio
import threading
import time 
import time as time_module

class VoiceToTextConverter:
    def __init__(self):
        # åˆå§‹åŒ–å‚æ•°
        self.recording = False
        self.audio_data = None
        self.samplerate = 16000  # é‡‡æ ·ç‡
        self.channels = 1        # å•å£°é“
        # é™éŸ³æ£€æµ‹å‚æ•°
        self.silence_threshold = 0.02  # é™éŸ³é˜ˆå€¼(æŒ¯å¹…)
        self.silence_duration = 3 # é™éŸ³æŒç»­æ—¶é—´(ç§’)
        self.last_speech_time = time.time()  # æœ€åè¯­éŸ³æ—¶é—´
        self.recording_event = threading.Event()  # åˆå§‹åŒ–äº‹ä»¶æ ‡å¿—
        self.last_transcription = ""  # å­˜å‚¨æœ€æ–°è½¬å½•ç»“æœ
        self.lock = threading.Lock()  # æ·»åŠ çº¿ç¨‹é”ç¡®ä¿å˜é‡åŒæ­¥
        # æ˜¾å¼æŒ‡å®šdeviceä¸ºcpuå¹¶ä½¿ç”¨fp32ç²¾åº¦ä»¥é¿å…è­¦å‘Š
        # è‡ªåŠ¨æ£€æµ‹GPUï¼Œå¦‚æœå¯ç”¨åˆ™ä½¿ç”¨cudaï¼Œå¦åˆ™ä½¿ç”¨cpu
        device = "cuda" if torch.cuda.is_available() else "cpu"
        #print(f"ä½¿ç”¨è®¾å¤‡: {device}")
        self.model = whisper.load_model("base", device=device)  # åŠ è½½é‡åŒ–æ¨¡å‹å‡å°ä½“ç§¯å¹¶åŠ é€Ÿæ¨ç†
        self.output_file = 'recording.wav'  # ä¸´æ—¶éŸ³é¢‘æ–‡ä»¶

        # ç§»é™¤è‡ªåŠ¨å¼€å§‹å½•éŸ³ï¼Œæ”¹ä¸ºæ‰‹åŠ¨è°ƒç”¨record_and_transcribe()
        pass

    def record_and_transcribe(self):
        """å¼€å§‹å½•éŸ³å¹¶åœ¨æ£€æµ‹åˆ°é™éŸ³åè¿”å›è¯†åˆ«ç»“æœ"""
        self.start_recording()
        # ç­‰å¾…å½•éŸ³çº¿ç¨‹å®Œæˆ
        self.recording_thread.join()
        with self.lock:
            return self.last_transcription

    def start_recording(self):
        """å¼€å§‹å½•éŸ³"""
        self.recording = True
        self.audio_data = []
        #print("å¼€å§‹å½•éŸ³...")

        # åœ¨æ–°çº¿ç¨‹ä¸­å½•éŸ³ï¼Œé¿å…é˜»å¡ä¸»çº¿ç¨‹
        self.recording_thread = threading.Thread(target=self.record_audio)
        self.recording_thread.start()

    def record_audio(self):
        """å½•éŸ³å‡½æ•° - å®æ—¶å¤„ç†éŸ³é¢‘æµå¹¶æ£€æµ‹é™éŸ³"""
        def callback(indata, frames, time, status):
            # if status:
            #     print(f"å½•éŸ³çŠ¶æ€: {status}")
            self.audio_data.append(indata.copy())
            
            # è®¡ç®—éŸ³é¢‘æŒ¯å¹…(éŸ³é‡)
            amplitude = np.max(np.abs(indata))
            current_time = time_module.time()  # ä½¿ç”¨é‡å‘½åçš„timeæ¨¡å—é¿å…å†²çª
            
            # å¦‚æœæŒ¯å¹…è¶…è¿‡é˜ˆå€¼ï¼Œæ›´æ–°æœ€åè¯­éŸ³æ—¶é—´
            if amplitude > self.silence_threshold:
                self.last_speech_time = current_time
            
            # æ£€æŸ¥æ˜¯å¦è¶…è¿‡é™éŸ³æŒç»­æ—¶é—´
            if current_time - self.last_speech_time > self.silence_duration:
                self.stop_recording()

        # åˆ›å»ºå½•éŸ³æµ
        with sd.InputStream(samplerate=self.samplerate, channels=self.channels, callback=callback):
            while self.recording and not self.recording_event.is_set():
                # ä»…ä¿æŒå¾ªç¯è¿è¡Œï¼Œç­‰å¾…é™éŸ³æ£€æµ‹è§¦å‘åœæ­¢
                time.sleep(0.1)
                
                # æ£€æŸ¥é™éŸ³çŠ¶æ€
                if time.time() - self.last_speech_time > self.silence_duration:
                    self.stop_recording()
                    break

    def process_audio_fragment(self):
        """å¤„ç†éŸ³é¢‘ç‰‡æ®µå¹¶å®æ—¶è½¬å½•"""
        if not self.audio_data:
            return

        # æå–å¹¶æ¸…ç©ºå½“å‰éŸ³é¢‘æ•°æ®
        audio_array = np.concatenate(self.audio_data, axis=0)
        self.audio_data = []

        # ä¿å­˜ä¸ºä¸´æ—¶æ–‡ä»¶
        temp_file = 'temp_recording.wav'
        wavio.write(temp_file, audio_array, self.samplerate, sampwidth=2)

        # ä½¿ç”¨whisperè¿›è¡Œå®æ—¶è¯­éŸ³è¯†åˆ«
        try:
            # ä½¿ç”¨æ›´çŸ­çš„æ¸©åº¦è®¾ç½®å’Œå•é€šé“å¤„ç†ä»¥åŠ å¿«é€Ÿåº¦
            result = self.model.transcribe(
                temp_file, 
                language='zh', 
                fp16=torch.cuda.is_available(),  # æ ¹æ®è®¾å¤‡è‡ªåŠ¨é€‰æ‹©ç²¾åº¦
                initial_prompt="æ—¥å¸¸å¯¹è¯",
                temperature=0.0,
                condition_on_previous_text=True,  # ç¡®å®šæ€§è¾“å‡º
                no_speech_threshold=0.6  # é™ä½æ— è¯­éŸ³é˜ˆå€¼
            )
            transcribed_text = result['text'].strip()
            # ç¡®ä¿ä¸­æ–‡æ­£å¸¸æ˜¾ç¤º
            transcribed_text = transcribed_text.encode('utf-8').decode('utf-8')
            if transcribed_text:
                # æ›´æ–°æœ€åè¯­éŸ³æ—¶é—´
                self.last_speech_time = time.time()
                return transcribed_text
        except Exception as e:
            print(f"è¯­éŸ³è¯†åˆ«å‡ºé”™: {str(e)}")
            return ""

        # åˆ é™¤ä¸´æ—¶æ–‡ä»¶
        import os
        if os.path.exists(temp_file):
            os.remove(temp_file)

    def stop_recording(self):
        """åœæ­¢å½•éŸ³å¹¶å¤„ç†æœ€åçš„éŸ³é¢‘ç‰‡æ®µ"""
        if not self.recording:
            return

        self.recording = False
        self.recording_event.set()  # è§¦å‘äº‹ä»¶é€šçŸ¥çº¿ç¨‹ç»“æŸ
        # ç¡®ä¿ä¸åœ¨å½“å‰çº¿ç¨‹ä¸­è°ƒç”¨join


        # å¤„ç†å‰©ä½™çš„éŸ³é¢‘æ•°æ®
        final_text = self.process_audio_fragment()
        
        # è¾“å‡ºæœ€ç»ˆè¯†åˆ«ç»“æœ
        if final_text:
            with self.lock:
                self.last_transcription = final_text
            print(f"è¯†åˆ«ç»“æœ: {final_text}")
        
        # ä»…è¿”å›è¯†åˆ«ç»“æœï¼Œä¸ä¿å­˜åˆ°æ–‡ä»¶
        if not final_text:
            print("æœªæ£€æµ‹åˆ°æœ‰æ•ˆè¯­éŸ³å†…å®¹")

        print("å½•éŸ³å·²åœæ­¢")
        return final_text

    def run(self):
        """è¿è¡Œç¨‹åº - æŒç»­è¿è¡Œç›´åˆ°ç”¨æˆ·æŒ‰Ctrl+Cé€€å‡º"""
        try:
            # æŒç»­è¿è¡Œä¸»å¾ªç¯
            while True:
                time.sleep(0.1)
        except KeyboardInterrupt:
            self.stop_recording()
            print("ç¨‹åºå·²é€€å‡º")

if __name__ == "__main__":
    # ç¡®ä¿ä¸­æ–‡æ˜¾ç¤ºæ­£å¸¸
    
    while True:

        vtt = VoiceToTextConverter()
        transcribed_text = vtt.record_and_transcribe()
        if not transcribed_text:
            print("ğŸ”‡ æœªæ£€æµ‹åˆ°è¯­éŸ³è¾“å…¥ï¼Œè¯·é‡è¯•...")
            continue
        print(f"è¯†åˆ«ç»“æœ: {transcribed_text}")
        transcribed_text=""
        if transcribed_text == "é€€å‡º":
            break

